{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Many 0\n",
      "people 5\n",
      "eat 12\n",
      "cereal 16\n",
      "for 23\n",
      "breakfast 27\n",
      ". 36\n",
      "Ted 37\n",
      "goes 41\n",
      "to 46\n",
      "the 49\n",
      "gym 53\n",
      "and 57\n",
      "exercises 61\n",
      "three 71\n",
      "times 77\n",
      "a 83\n",
      "week 85\n",
      ". 89\n",
      "Yuriko 90\n",
      "and 97\n",
      "Mina 101\n",
      "are 106\n",
      "going 110\n",
      "to 116\n",
      "Hawaii 119\n",
      "this 126\n",
      "summer 131\n",
      ". 137\n",
      "These 139\n",
      "examples 145\n",
      "show 154\n",
      "us 159\n",
      "that 162\n",
      "simple 167\n",
      "sentences 174\n",
      "can 184\n",
      "have 188\n",
      "more 193\n",
      "than 198\n",
      "one 203\n",
      "subject 207\n",
      "and 215\n",
      "more 219\n",
      "than 224\n",
      "one 229\n",
      "verb 233\n",
      ", 237\n",
      "but 239\n",
      "only 243\n",
      "express 248\n",
      "one 256\n",
      "idea 260\n",
      "or 265\n",
      "complete 268\n",
      "thought 277\n",
      ". 284\n"
     ]
    }
   ],
   "source": [
    "#Assignment No 1 NLP\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "input = (\n",
    "    \"Many people eat cereal for breakfast.\"\n",
    "    \"Ted goes to the gym and exercises three times a week.\"\n",
    "    \"Yuriko and Mina are going to Hawaii this summer.\"\n",
    "    \" These examples show us that simple sentences can have more than one\"\n",
    "    \" subject and more than one verb, but only express one idea or complete thought.\"\n",
    ")\n",
    "\n",
    "# Tokens \n",
    "about_doc = nlp(input)\n",
    "\n",
    "for token in about_doc:\n",
    "    print (token, token.idx)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[people, eat, cereal, breakfast, ., Ted, goes, gym, exercises, times, week, ., Yuriko, Mina, going, Hawaii, summer, ., examples, simple, sentences, subject, verb, ,, express, idea, complete, thought, .]\n"
     ]
    }
   ],
   "source": [
    "# Stop words\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "about_doc = nlp(input)\n",
    "print([token for token in about_doc if not token.is_stop])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOKEN: Many\n",
      "=====\n",
      "TAG: JJ         POS: ADJ\n",
      "EXPLANATION: adjective (English), other noun-modifier (Chinese)\n",
      "\n",
      "TOKEN: people\n",
      "=====\n",
      "TAG: NNS        POS: NOUN\n",
      "EXPLANATION: noun, plural\n",
      "\n",
      "TOKEN: eat\n",
      "=====\n",
      "TAG: VBP        POS: VERB\n",
      "EXPLANATION: verb, non-3rd person singular present\n",
      "\n",
      "TOKEN: cereal\n",
      "=====\n",
      "TAG: NN         POS: NOUN\n",
      "EXPLANATION: noun, singular or mass\n",
      "\n",
      "TOKEN: for\n",
      "=====\n",
      "TAG: IN         POS: ADP\n",
      "EXPLANATION: conjunction, subordinating or preposition\n",
      "\n",
      "TOKEN: breakfast\n",
      "=====\n",
      "TAG: NN         POS: NOUN\n",
      "EXPLANATION: noun, singular or mass\n",
      "\n",
      "TOKEN: .\n",
      "=====\n",
      "TAG: .          POS: PUNCT\n",
      "EXPLANATION: punctuation mark, sentence closer\n",
      "\n",
      "TOKEN: Ted\n",
      "=====\n",
      "TAG: NNP        POS: PROPN\n",
      "EXPLANATION: noun, proper singular\n",
      "\n",
      "TOKEN: goes\n",
      "=====\n",
      "TAG: VBZ        POS: VERB\n",
      "EXPLANATION: verb, 3rd person singular present\n",
      "\n",
      "TOKEN: to\n",
      "=====\n",
      "TAG: IN         POS: ADP\n",
      "EXPLANATION: conjunction, subordinating or preposition\n",
      "\n",
      "TOKEN: the\n",
      "=====\n",
      "TAG: DT         POS: DET\n",
      "EXPLANATION: determiner\n",
      "\n",
      "TOKEN: gym\n",
      "=====\n",
      "TAG: NN         POS: NOUN\n",
      "EXPLANATION: noun, singular or mass\n",
      "\n",
      "TOKEN: and\n",
      "=====\n",
      "TAG: CC         POS: CCONJ\n",
      "EXPLANATION: conjunction, coordinating\n",
      "\n",
      "TOKEN: exercises\n",
      "=====\n",
      "TAG: NNS        POS: NOUN\n",
      "EXPLANATION: noun, plural\n",
      "\n",
      "TOKEN: three\n",
      "=====\n",
      "TAG: CD         POS: NUM\n",
      "EXPLANATION: cardinal number\n",
      "\n",
      "TOKEN: times\n",
      "=====\n",
      "TAG: NNS        POS: NOUN\n",
      "EXPLANATION: noun, plural\n",
      "\n",
      "TOKEN: a\n",
      "=====\n",
      "TAG: DT         POS: DET\n",
      "EXPLANATION: determiner\n",
      "\n",
      "TOKEN: week\n",
      "=====\n",
      "TAG: NN         POS: NOUN\n",
      "EXPLANATION: noun, singular or mass\n",
      "\n",
      "TOKEN: .\n",
      "=====\n",
      "TAG: .          POS: PUNCT\n",
      "EXPLANATION: punctuation mark, sentence closer\n",
      "\n",
      "TOKEN: Yuriko\n",
      "=====\n",
      "TAG: NNP        POS: PROPN\n",
      "EXPLANATION: noun, proper singular\n",
      "\n",
      "TOKEN: and\n",
      "=====\n",
      "TAG: CC         POS: CCONJ\n",
      "EXPLANATION: conjunction, coordinating\n",
      "\n",
      "TOKEN: Mina\n",
      "=====\n",
      "TAG: NNP        POS: PROPN\n",
      "EXPLANATION: noun, proper singular\n",
      "\n",
      "TOKEN: are\n",
      "=====\n",
      "TAG: VBP        POS: AUX\n",
      "EXPLANATION: verb, non-3rd person singular present\n",
      "\n",
      "TOKEN: going\n",
      "=====\n",
      "TAG: VBG        POS: VERB\n",
      "EXPLANATION: verb, gerund or present participle\n",
      "\n",
      "TOKEN: to\n",
      "=====\n",
      "TAG: IN         POS: ADP\n",
      "EXPLANATION: conjunction, subordinating or preposition\n",
      "\n",
      "TOKEN: Hawaii\n",
      "=====\n",
      "TAG: NNP        POS: PROPN\n",
      "EXPLANATION: noun, proper singular\n",
      "\n",
      "TOKEN: this\n",
      "=====\n",
      "TAG: DT         POS: DET\n",
      "EXPLANATION: determiner\n",
      "\n",
      "TOKEN: summer\n",
      "=====\n",
      "TAG: NN         POS: NOUN\n",
      "EXPLANATION: noun, singular or mass\n",
      "\n",
      "TOKEN: .\n",
      "=====\n",
      "TAG: .          POS: PUNCT\n",
      "EXPLANATION: punctuation mark, sentence closer\n",
      "\n",
      "TOKEN: These\n",
      "=====\n",
      "TAG: DT         POS: DET\n",
      "EXPLANATION: determiner\n",
      "\n",
      "TOKEN: examples\n",
      "=====\n",
      "TAG: NNS        POS: NOUN\n",
      "EXPLANATION: noun, plural\n",
      "\n",
      "TOKEN: show\n",
      "=====\n",
      "TAG: VBP        POS: VERB\n",
      "EXPLANATION: verb, non-3rd person singular present\n",
      "\n",
      "TOKEN: us\n",
      "=====\n",
      "TAG: PRP        POS: PRON\n",
      "EXPLANATION: pronoun, personal\n",
      "\n",
      "TOKEN: that\n",
      "=====\n",
      "TAG: IN         POS: SCONJ\n",
      "EXPLANATION: conjunction, subordinating or preposition\n",
      "\n",
      "TOKEN: simple\n",
      "=====\n",
      "TAG: JJ         POS: ADJ\n",
      "EXPLANATION: adjective (English), other noun-modifier (Chinese)\n",
      "\n",
      "TOKEN: sentences\n",
      "=====\n",
      "TAG: NNS        POS: NOUN\n",
      "EXPLANATION: noun, plural\n",
      "\n",
      "TOKEN: can\n",
      "=====\n",
      "TAG: MD         POS: AUX\n",
      "EXPLANATION: verb, modal auxiliary\n",
      "\n",
      "TOKEN: have\n",
      "=====\n",
      "TAG: VB         POS: VERB\n",
      "EXPLANATION: verb, base form\n",
      "\n",
      "TOKEN: more\n",
      "=====\n",
      "TAG: JJR        POS: ADJ\n",
      "EXPLANATION: adjective, comparative\n",
      "\n",
      "TOKEN: than\n",
      "=====\n",
      "TAG: IN         POS: ADP\n",
      "EXPLANATION: conjunction, subordinating or preposition\n",
      "\n",
      "TOKEN: one\n",
      "=====\n",
      "TAG: CD         POS: NUM\n",
      "EXPLANATION: cardinal number\n",
      "\n",
      "TOKEN: subject\n",
      "=====\n",
      "TAG: NN         POS: NOUN\n",
      "EXPLANATION: noun, singular or mass\n",
      "\n",
      "TOKEN: and\n",
      "=====\n",
      "TAG: CC         POS: CCONJ\n",
      "EXPLANATION: conjunction, coordinating\n",
      "\n",
      "TOKEN: more\n",
      "=====\n",
      "TAG: JJR        POS: ADJ\n",
      "EXPLANATION: adjective, comparative\n",
      "\n",
      "TOKEN: than\n",
      "=====\n",
      "TAG: IN         POS: ADP\n",
      "EXPLANATION: conjunction, subordinating or preposition\n",
      "\n",
      "TOKEN: one\n",
      "=====\n",
      "TAG: CD         POS: NUM\n",
      "EXPLANATION: cardinal number\n",
      "\n",
      "TOKEN: verb\n",
      "=====\n",
      "TAG: NN         POS: NOUN\n",
      "EXPLANATION: noun, singular or mass\n",
      "\n",
      "TOKEN: ,\n",
      "=====\n",
      "TAG: ,          POS: PUNCT\n",
      "EXPLANATION: punctuation mark, comma\n",
      "\n",
      "TOKEN: but\n",
      "=====\n",
      "TAG: CC         POS: CCONJ\n",
      "EXPLANATION: conjunction, coordinating\n",
      "\n",
      "TOKEN: only\n",
      "=====\n",
      "TAG: RB         POS: ADV\n",
      "EXPLANATION: adverb\n",
      "\n",
      "TOKEN: express\n",
      "=====\n",
      "TAG: VB         POS: VERB\n",
      "EXPLANATION: verb, base form\n",
      "\n",
      "TOKEN: one\n",
      "=====\n",
      "TAG: CD         POS: NUM\n",
      "EXPLANATION: cardinal number\n",
      "\n",
      "TOKEN: idea\n",
      "=====\n",
      "TAG: NN         POS: NOUN\n",
      "EXPLANATION: noun, singular or mass\n",
      "\n",
      "TOKEN: or\n",
      "=====\n",
      "TAG: CC         POS: CCONJ\n",
      "EXPLANATION: conjunction, coordinating\n",
      "\n",
      "TOKEN: complete\n",
      "=====\n",
      "TAG: JJ         POS: ADJ\n",
      "EXPLANATION: adjective (English), other noun-modifier (Chinese)\n",
      "\n",
      "TOKEN: thought\n",
      "=====\n",
      "TAG: NN         POS: NOUN\n",
      "EXPLANATION: noun, singular or mass\n",
      "\n",
      "TOKEN: .\n",
      "=====\n",
      "TAG: .          POS: PUNCT\n",
      "EXPLANATION: punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "#Tokenization\n",
    "about_doc = nlp(input)\n",
    "for token in about_doc:\n",
    "    print(\n",
    "        f\"\"\"\n",
    "TOKEN: {str(token)}\n",
    "=====\n",
    "TAG: {str(token.tag_):10} POS: {token.pos_}\n",
    "EXPLANATION: {spacy.explain(token.tag_)}\"\"\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Many : many\n",
      "                goes : go\n",
      "           exercises : exercise\n",
      "               times : time\n",
      "                 are : be\n",
      "               going : go\n",
      "               These : these\n",
      "            examples : example\n",
      "                  us : we\n",
      "           sentences : sentence\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "conference_help_doc = nlp(input)\n",
    "for token in conference_help_doc:\n",
    "    if str(token) != str(token.lemma_):\n",
    "        print(f\"{str(token):>20} : {str(token.lemma_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/exam/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Many people eat cereal for breakfast.Ted goes to the gym and exercises three times a week.Yuriko and Mina are going to Hawaii this summer.',\n",
       " 'These examples show us that simple sentences can have more than one subject and more than one verb, but only express one idea or complete thought.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/exam/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Many',\n",
       " 'people',\n",
       " 'eat',\n",
       " 'cereal',\n",
       " 'for',\n",
       " 'breakfast.Ted',\n",
       " 'goes',\n",
       " 'to',\n",
       " 'the',\n",
       " 'gym',\n",
       " 'and',\n",
       " 'exercises',\n",
       " 'three',\n",
       " 'times',\n",
       " 'a',\n",
       " 'week.Yuriko',\n",
       " 'and',\n",
       " 'Mina',\n",
       " 'are',\n",
       " 'going',\n",
       " 'to',\n",
       " 'Hawaii',\n",
       " 'this',\n",
       " 'summer',\n",
       " '.',\n",
       " 'These',\n",
       " 'examples',\n",
       " 'show',\n",
       " 'us',\n",
       " 'that',\n",
       " 'simple',\n",
       " 'sentences',\n",
       " 'can',\n",
       " 'have',\n",
       " 'more',\n",
       " 'than',\n",
       " 'one',\n",
       " 'subject',\n",
       " 'and',\n",
       " 'more',\n",
       " 'than',\n",
       " 'one',\n",
       " 'verb',\n",
       " ',',\n",
       " 'but',\n",
       " 'only',\n",
       " 'express',\n",
       " 'one',\n",
       " 'idea',\n",
       " 'or',\n",
       " 'complete',\n",
       " 'thought',\n",
       " '.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_quote = word_tokenize(input)\n",
    "words_in_quote"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
